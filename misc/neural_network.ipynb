{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from audio import read_mfcc\n",
    "from batcher import sample_from_mfcc\n",
    "from constants import SAMPLE_RATE, NUM_FRAMES\n",
    "from conv_models import DeepSpeakerModel\n",
    "from test import batch_cosine_similarity\n",
    "from scipy.stats import entropy\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_cli = 'nn.py' in sys.argv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pre-trained Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_cli:\n",
    "    print('Loading pre-trained model...')\n",
    "model = DeepSpeakerModel()\n",
    "model.m.load_weights('ResCNN_triplet_training_checkpoint_265.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoneOfTheAboveDataset(Dataset):\n",
    "    def __init__(self, in_dataset_dir, not_in_dataset_dir, limit=1000):\n",
    "        outputs = []\n",
    "        labels = []\n",
    "\n",
    "        # iterate through true samples\n",
    "        in_speakers = [f for f in os.listdir(in_dataset_dir) if f != '.DS_Store']\n",
    "        for speaker in in_speakers:\n",
    "            # only train on the first 5 clips for each speaker\n",
    "            for clip in os.listdir(f'{in_dataset_dir}/{speaker}'):\n",
    "                if 'npy' not in clip:\n",
    "                    continue\n",
    "\n",
    "                output = np.load(f'{in_dataset_dir}/{speaker}/{clip}')[0]\n",
    "                outputs.append(output)\n",
    "                labels.append(1)\n",
    "\n",
    "        # iterate through false samples\n",
    "        out_speakers = [f for f in os.listdir(not_in_dataset_dir) if f != '.DS_Store']\n",
    "\n",
    "        random.shuffle(out_speakers)\n",
    "\n",
    "        out_speakers = out_speakers[:limit]\n",
    "\n",
    "        for speaker in out_speakers:\n",
    "            for clip in os.listdir(f'{not_in_dataset_dir}/{speaker}'):\n",
    "                if 'npy' not in clip:\n",
    "                    continue\n",
    "\n",
    "                output = np.load(f'{not_in_dataset_dir}/{speaker}/{clip}')[0]\n",
    "                outputs.append(output)\n",
    "                labels.append(0)\n",
    "\n",
    "        self.outputs = np.array(outputs)\n",
    "        self.labels = np.array(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.outputs[idx], self.labels[idx]      \n",
    "    \n",
    "\n",
    "class ClassifierDataset(Dataset):\n",
    "    \"\"\"Load numpy files from directory structure where each numpy file represents\n",
    "    the extracted features from the pre-trained model\"\"\"\n",
    "    \n",
    "    def __init__(self, dirs, train):\n",
    "        self.dir = dir\n",
    "\n",
    "        outputs = []\n",
    "        labels = []\n",
    "\n",
    "        speakers = [f for f in os.listdir(dir) if f != '.DS_Store']\n",
    "        for i, speaker in enumerate(speakers):\n",
    "            for clip in os.listdir(f'{dir}/{speaker}'):\n",
    "                if 'npy' not in clip:\n",
    "                    continue\n",
    "\n",
    "                # we want to only train on clips 0 and 1\n",
    "                if train:\n",
    "                    if '0' not in clip:\n",
    "                        continue\n",
    "\n",
    "                output = np.load(f'{dir}/{speaker}/{clip}')\n",
    "                output = output[0]\n",
    "\n",
    "                outputs.append(output)\n",
    "                labels.append(i)\n",
    "\n",
    "        self.outputs = np.array(outputs)\n",
    "        self.labels = np.array(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.outputs[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "17\n"
    }
   ],
   "source": [
    "# note: this assumes you have run `split_audio()` and\n",
    "# `create_and_store_mfcc()` from `audio_processing.ipynb`\n",
    "dir = 'mfcc/split/SherlockHolmes'\n",
    "\n",
    "classes = [f for f in os.listdir(dir) if f != '.DS_Store']\n",
    "\n",
    "training_dataset = ClassifierDataset(dir, train=True)\n",
    "testing_dataset = ClassifierDataset(dir, train=False)\n",
    "\n",
    "print(len(training_dataset))\n",
    "\n",
    "none_of_the_above_dataset = NoneOfTheAboveDataset('mfcc/split/SherlockHolmes', 'mfcc/split/Accents', limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# don't shuffle test data, we want clips 0->1 trained in order\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=batch_size)\n",
    "none_of_the_above_loader = DataLoader(none_of_the_above_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoneOfTheAboveClassifier(nn.Module):\n",
    "    \"\"\"Classifier to determine whether a speaker is included\n",
    "    in the training set or not. Binary output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NoneOfTheAboveClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"Define a simple linear neural network\n",
    "\n",
    "    Args:\n",
    "        num_classes: the number of classes we are classifying\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train first network\n",
    "none_of_the_above_classifier = NoneOfTheAboveClassifier()\n",
    "num_epochs = 1000\n",
    "lr = 0.003\n",
    "\n",
    "optimizer = optim.Adam(none_of_the_above_classifier.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "losses = []\n",
    "for epoch_num, epoch in enumerate(range(num_epochs)):\n",
    "    none_of_the_above_classifier.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    for batch_index, (inputs, labels) in enumerate(none_of_the_above_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = none_of_the_above_classifier(inputs)\n",
    "\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "        outputs = outputs.type(torch.FloatTensor)[:, 0]\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_cli:\n",
    "    print('Training...')\n",
    "\n",
    "num_classes = len(classes)\n",
    "classifier = Classifier(num_classes=num_classes)\n",
    "\n",
    "num_epochs = 5000\n",
    "lr = 0.003\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=lr)\n",
    "\n",
    "for epoch_num, epoch in enumerate(range(num_epochs)):\n",
    "    classifier.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    for batch_index, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = classifier(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of mikie: 100.0% (13/13)\nAccuracy of hailey: 100.0% (10/10)\nAccuracy of crystal: 100.0% (10/10)\nAccuracy of mei: 100.0% (13/13)\nAccuracy of changhan: 100.0% (17/17)\nAccuracy of daphne: 81.82% (9/11)\nAccuracy of swadhin: 100.0% (17/17)\nAccuracy of stephanie: 100.0% (9/9)\nAccuracy of cheryl: 100.0% (12/12)\nAccuracy of chad: 50.0% (5/10)\nAccuracy of ethan: 100.0% (10/10)\n0.946969696969697\n"
    }
   ],
   "source": [
    "classes = [f for f in os.listdir(dir) if f != '.DS_Store']\n",
    "\n",
    "class_correct = [0 for i in range(len(classes))]\n",
    "class_total = [0 for i in range(len(classes))]\n",
    "\n",
    "ARGMAX_THRESHOLD = 0.5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = classifier(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "\n",
    "        for i, (output, label) in enumerate(zip(outputs, labels)):\n",
    "            class_total[label] += 1\n",
    "\n",
    "            if c[i].item() and max(output) >= ARGMAX_THRESHOLD:\n",
    "                class_correct[label] += 1\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    print(f'Accuracy of {classes[i]}: {round(100 * class_correct[i] / class_total[i], 2)}% ({class_correct[i]}/{class_total[i]})')\n",
    "print(sum(class_correct) / sum(class_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINARY_THRESHOLD = 0.4\n",
    "MAX_THRESHOLD = 0.4\n",
    "\n",
    "def make_prediction(audio_path):\n",
    "    mfcc = sample_from_mfcc(read_mfcc(audio_path, SAMPLE_RATE), NUM_FRAMES)\n",
    "    predict = model.m.predict(np.expand_dims(mfcc, axis=0))\n",
    "    predict = torch.from_numpy(predict)\n",
    "\n",
    "    # first see if it passes thresholding/junk class\n",
    "    binary_classification_value = float(none_of_the_above_classifier(predict)[0][0])\n",
    "    if binary_classification_value < BINARY_THRESHOLD:\n",
    "        return None\n",
    "\n",
    "    # run through the actual classifier\n",
    "    result = classifier(predict)\n",
    "    argmax = torch.argmax(result)\n",
    "\n",
    "    if result[0][argmax] < MAX_THRESHOLD:\n",
    "        return None\n",
    "\n",
    "    return classes[argmax]\n",
    "\n",
    "\n",
    "def make_prediction_with_features(numpy_path):\n",
    "    numpy_array = np.load(numpy_path)\n",
    "    predict = torch.from_numpy(numpy_array)\n",
    "\n",
    "    binary_classification_value = float(none_of_the_above_classifier(predict)[0][0])\n",
    "\n",
    "    if binary_classification_value < BINARY_THRESHOLD:\n",
    "        return None\n",
    "\n",
    "    # run through the actual classifier\n",
    "    result = classifier(predict)\n",
    "    argmax = torch.argmax(result)\n",
    "\n",
    "    if result[0][argmax] < MAX_THRESHOLD:\n",
    "        return None\n",
    "        \n",
    "    return classes[argmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(0.4651, grad_fn=<SelectBackward>)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'cheryl'"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "make_prediction('audio/split/SherlockHolmes/ethan/SherlockHolmes_2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_binary_classifier():\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for dir in ['Accents', 'SherlockHolmes']:\n",
    "        test_classes = os.listdir(f'mfcc/split/{dir}')\n",
    "        for test_class in test_classes:\n",
    "            upper, lower = (0, 20) if dir == 'Accents' else (5, 20)\n",
    "\n",
    "            for i in range(upper, lower):\n",
    "                try:\n",
    "                    path = f'/Users/ethanzh/Code/automatic-speaker-recognition/mfcc/split/{dir}/{test_class}/{dir}_{i}.npy'\n",
    "                    result = str(make_prediction_with_features(path))\n",
    "                    y_pred.append(result)\n",
    "\n",
    "                    if dir == 'Accents':\n",
    "                        y_true.append(str(None))\n",
    "                    else:\n",
    "                        y_true.append(test_class)\n",
    "\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "t/p    mikie     hailey    crystal   mei       changhan  daphne    swadhin   stephanie cheryl    chad      ethan     None      \n    mikie           8.0                                                                                                               \n    hailey                    5.0                                                                                                     \n    crystal                             5.0                                                                                           \n    mei                                           8.0                                                                                 \n    changhan                                               12.0                                                                       \n    daphne                                                            5.0                 1.0                                         \n    swadhin                                                                    12.0                                                   \n    stephanie                                                                             4.0                                         \n    cheryl                                                                                          7.0                               \n    chad                                                    1.0                                     1.0       2.0                 1.0 \n    ethan                                                                                                               5.0           \n    None          190.0     143.0      48.0     258.0     187.0     121.0     240.0     200.0     112.0      29.0     126.0    3264.0 \nWeighted F1 score: 0.7868610314215307\nMicro F1 score: 0.6680680680680681\nMacro F1 score: 0.14871810323119627\n"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "\n",
    "labels = [f for f in os.listdir(f'mfcc/split/SherlockHolmes') if f != '.DS_Store']\n",
    "labels.append(str(None))\n",
    "\n",
    "y_pred, y_true = test_binary_classifier()\n",
    "\n",
    "print_confusion_matrix(y_true, y_pred, labels, hide_zeroes=True)\n",
    "\n",
    "weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f'Weighted F1 score: {weighted_f1}')\n",
    "print(f'Micro F1 score: {micro_f1}')\n",
    "print(f'Macro F1 score: {macro_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_confusion_matrix(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    labels: Optional[List] = None,\n",
    "    hide_zeroes: bool = False,\n",
    "    hide_diagonal: bool = False,\n",
    "    hide_threshold: Optional[float] = None,\n",
    "):\n",
    "    \"\"\"Print a nicely formatted confusion matrix with labelled rows and columns.\n",
    "\n",
    "    Predicted labels are in the top horizontal header, true labels on the vertical header.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): ground truth labels\n",
    "        y_pred (np.ndarray): predicted labels\n",
    "        labels (Optional[List], optional): list of all labels. If None, then all labels present in the data are\n",
    "            displayed. Defaults to None.\n",
    "        hide_zeroes (bool, optional): replace zero-values with an empty cell. Defaults to False.\n",
    "        hide_diagonal (bool, optional): replace true positives (diagonal) with empty cells. Defaults to False.\n",
    "        hide_threshold (Optional[float], optional): replace values below this threshold with empty cells. Set to None\n",
    "            to display all values. Defaults to None.\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    # find which fixed column width will be used for the matrix\n",
    "    columnwidth = max(\n",
    "        [len(str(x)) for x in labels] + [5]\n",
    "    )  # 5 is the minimum column width, otherwise the longest class name\n",
    "    empty_cell = ' ' * columnwidth\n",
    "\n",
    "    # top-left cell of the table that indicates that top headers are predicted classes, left headers are true classes\n",
    "    padding_fst_cell = (columnwidth - 3) // 2  # double-slash is int division\n",
    "    fst_empty_cell = padding_fst_cell * ' ' + 't/p' + ' ' * (columnwidth - padding_fst_cell - 3)\n",
    "\n",
    "    # Print header\n",
    "    print('    ' + fst_empty_cell, end=' ')\n",
    "    for label in labels:\n",
    "        print(f'{label:{columnwidth}}', end=' ')  # right-aligned label padded with spaces to columnwidth\n",
    "\n",
    "    print()  # newline\n",
    "    # Print rows\n",
    "    for i, label in enumerate(labels):\n",
    "        print(f'    {label:{columnwidth}}', end=' ')  # right-aligned label padded with spaces to columnwidth\n",
    "        for j in range(len(labels)):\n",
    "            # cell value padded to columnwidth with spaces and displayed with 1 decimal\n",
    "            cell = f'{cm[i, j]:{columnwidth}.1f}'\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = os.listdir('mfcc/split/Accents')\n",
    "\n",
    "results = []\n",
    "\n",
    "for test_class in test_classes:\n",
    "    for i in range(0, 5):\n",
    "        try:\n",
    "            path = f'/Users/ethanzh/Code/automatic-speaker-recognition/mfcc/split/Accents/{test_class}/Accents_{i}.npy'\n",
    "            result = make_prediction_with_features(path)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-speaker",
   "language": "python",
   "name": "deep-speaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}